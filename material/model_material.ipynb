{"cells":[{"cell_type":"code","execution_count":1,"id":"84dccb09","metadata":{"id":"84dccb09"},"outputs":[],"source":["import time\n","import numpy as np\n","import wandb\n","import random\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchinfo import summary\n","from torchvision import transforms, models\n","from material import MyDataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# def transform(proba):\n","#     t = transforms.Compose([\n","#         transforms.Resize((224, 224)),\n","#         transforms.RandomHorizontalFlip(p=proba),\n","#         transforms.RandomVerticalFlip(p=proba),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize(\n","#             [0.485, 0.456, 0.406],\n","#             [0.229, 0.224, 0.225]\n","#         )\n","#     ])\n","#     return t"]},{"cell_type":"code","execution_count":3,"id":"8f806c44","metadata":{},"outputs":[],"source":["# reproductability를 위한 코드\n","torch.manual_seed(1919)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(1919)\n","random.seed(1919)"]},{"cell_type":"code","execution_count":4,"id":"bbd930aa","metadata":{"id":"bbd930aa"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#gpu 사용을 위해 cuda 지정\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":5,"id":"34b905f1","metadata":{"id":"34b905f1","outputId":"87d041f9-38fa-411a-f0f1-fa8e80ed9656"},"outputs":[],"source":["# def transform(proba):\n","#     t = transforms.Compose([\n","#         transforms.Resize((224, 224)),\n","#         transforms.RandomHorizontalFlip(p=proba),\n","#         transforms.RandomVerticalFlip(p=proba),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize(\n","#             [0.485, 0.456, 0.406],\n","#             [0.229, 0.224, 0.225]\n","#         )\n","#     ])\n","#     return t"]},{"cell_type":"code","execution_count":6,"id":"45c74613","metadata":{},"outputs":[],"source":["# trainsets = []\n","# dirs = [\"leather/\", \"mesh_knit/\", \"suede/\", \"nylon/\"]\n","# prob = [0.25, 0.5, 1, 0.75]\n","\n","# for i in range(4):\n","#     dataset = MyDataset(dir='/home/compu/Documents/exports/material_merge/train/'+dirs[i],\n","#                         image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","#                         transforms=transform(prob[i]))\n","#     trainsets.append(dataset)\n","#     print(len(dataset))\n","\n","# trainset = torch.utils.data.ConcatDataset(trainsets)"]},{"cell_type":"code","execution_count":7,"id":"599cb9f2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["학습 데이터셋 크기: 8411\n","테스트 데이터셋 크기: 2691\n"]}],"source":["transforms_train = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        [0.485, 0.456, 0.406],\n","        [0.229, 0.224, 0.225]\n","    )\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        [0.485, 0.456, 0.406],\n","        [0.229, 0.224, 0.225]\n","    )\n","])\n","\n","trainset = MyDataset(dir='/home/compu/Documents/exports/material_merge/train/',\n","                     image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","                     transforms=transforms_train)\n","\n","testset = MyDataset(dir='/home/compu/Documents/exports/material_merge/test/',\n","                    image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","                    transforms=transforms_test)\n","\n","train_loader = DataLoader(trainset, batch_size=32, num_workers=8)\n","test_loader = DataLoader(testset, batch_size=32, num_workers=8)\n","\n","print('학습 데이터셋 크기:', len(trainset))\n","print('테스트 데이터셋 크기:', len(testset))"]},{"cell_type":"code","execution_count":8,"id":"417bdedb","metadata":{"id":"417bdedb"},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":9,"id":"915f2143","metadata":{"id":"915f2143","outputId":"68c1b339-70c1-44e3-fa3a-ae0badb41cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["===============================================================================================\n","Layer (type:depth-idx)                        Output Shape              Param #\n","===============================================================================================\n","MyModel                                       [1, 4]                    --\n","├─ResNet: 1-1                                 [1, 1000]                 --\n","│    └─Conv2d: 2-1                            [1, 64, 112, 112]         9,408\n","│    └─BatchNorm2d: 2-2                       [1, 64, 112, 112]         128\n","│    └─ReLU: 2-3                              [1, 64, 112, 112]         --\n","│    └─MaxPool2d: 2-4                         [1, 64, 56, 56]           --\n","│    └─Sequential: 2-5                        [1, 256, 56, 56]          --\n","│    │    └─Bottleneck: 3-1                   [1, 256, 56, 56]          75,008\n","│    │    └─Bottleneck: 3-2                   [1, 256, 56, 56]          70,400\n","│    │    └─Bottleneck: 3-3                   [1, 256, 56, 56]          70,400\n","│    └─Sequential: 2-6                        [1, 512, 28, 28]          --\n","│    │    └─Bottleneck: 3-4                   [1, 512, 28, 28]          379,392\n","│    │    └─Bottleneck: 3-5                   [1, 512, 28, 28]          280,064\n","│    │    └─Bottleneck: 3-6                   [1, 512, 28, 28]          280,064\n","│    │    └─Bottleneck: 3-7                   [1, 512, 28, 28]          280,064\n","│    └─Sequential: 2-7                        [1, 1024, 14, 14]         --\n","│    │    └─Bottleneck: 3-8                   [1, 1024, 14, 14]         1,512,448\n","│    │    └─Bottleneck: 3-9                   [1, 1024, 14, 14]         1,117,184\n","│    │    └─Bottleneck: 3-10                  [1, 1024, 14, 14]         1,117,184\n","│    │    └─Bottleneck: 3-11                  [1, 1024, 14, 14]         1,117,184\n","│    │    └─Bottleneck: 3-12                  [1, 1024, 14, 14]         1,117,184\n","│    │    └─Bottleneck: 3-13                  [1, 1024, 14, 14]         1,117,184\n","│    └─Sequential: 2-8                        [1, 2048, 7, 7]           --\n","│    │    └─Bottleneck: 3-14                  [1, 2048, 7, 7]           6,039,552\n","│    │    └─Bottleneck: 3-15                  [1, 2048, 7, 7]           4,462,592\n","│    │    └─Bottleneck: 3-16                  [1, 2048, 7, 7]           4,462,592\n","│    └─AdaptiveAvgPool2d: 2-9                 [1, 2048, 1, 1]           --\n","│    └─Linear: 2-10                           [1, 1000]                 2,049,000\n","├─Linear: 1-2                                 [1, 4]                    4,004\n","===============================================================================================\n","Total params: 25,561,036\n","Trainable params: 25,561,036\n","Non-trainable params: 0\n","Total mult-adds (G): 4.09\n","===============================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 177.83\n","Params size (MB): 102.24\n","Estimated Total Size (MB): 280.68\n","===============================================================================================\n"]}],"source":["class MyModel(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.model = models.resnet50(True)\n","        self.classifier = nn.Linear(1000, 4)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.classifier(x)\n","        return x\n","\n","model = MyModel().to(device)\n","print(summary(model, input_size=(1, 3, 224, 224)))"]},{"cell_type":"code","execution_count":10,"id":"e2fb3d7e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["model.conv1.weight False\n","model.bn1.weight True\n","model.bn1.bias True\n","model.layer1.0.conv1.weight False\n","model.layer1.0.bn1.weight True\n","model.layer1.0.bn1.bias True\n","model.layer1.0.conv2.weight False\n","model.layer1.0.bn2.weight True\n","model.layer1.0.bn2.bias True\n","model.layer1.0.conv3.weight False\n","model.layer1.0.bn3.weight True\n","model.layer1.0.bn3.bias True\n","model.layer1.0.downsample.0.weight False\n","model.layer1.0.downsample.1.weight False\n","model.layer1.0.downsample.1.bias False\n","model.layer1.1.conv1.weight False\n","model.layer1.1.bn1.weight True\n","model.layer1.1.bn1.bias True\n","model.layer1.1.conv2.weight False\n","model.layer1.1.bn2.weight True\n","model.layer1.1.bn2.bias True\n","model.layer1.1.conv3.weight False\n","model.layer1.1.bn3.weight True\n","model.layer1.1.bn3.bias True\n","model.layer1.2.conv1.weight False\n","model.layer1.2.bn1.weight True\n","model.layer1.2.bn1.bias True\n","model.layer1.2.conv2.weight False\n","model.layer1.2.bn2.weight True\n","model.layer1.2.bn2.bias True\n","model.layer1.2.conv3.weight False\n","model.layer1.2.bn3.weight True\n","model.layer1.2.bn3.bias True\n","model.layer2.0.conv1.weight False\n","model.layer2.0.bn1.weight True\n","model.layer2.0.bn1.bias True\n","model.layer2.0.conv2.weight False\n","model.layer2.0.bn2.weight True\n","model.layer2.0.bn2.bias True\n","model.layer2.0.conv3.weight False\n","model.layer2.0.bn3.weight True\n","model.layer2.0.bn3.bias True\n","model.layer2.0.downsample.0.weight False\n","model.layer2.0.downsample.1.weight False\n","model.layer2.0.downsample.1.bias False\n","model.layer2.1.conv1.weight False\n","model.layer2.1.bn1.weight True\n","model.layer2.1.bn1.bias True\n","model.layer2.1.conv2.weight False\n","model.layer2.1.bn2.weight True\n","model.layer2.1.bn2.bias True\n","model.layer2.1.conv3.weight False\n","model.layer2.1.bn3.weight True\n","model.layer2.1.bn3.bias True\n","model.layer2.2.conv1.weight False\n","model.layer2.2.bn1.weight True\n","model.layer2.2.bn1.bias True\n","model.layer2.2.conv2.weight False\n","model.layer2.2.bn2.weight True\n","model.layer2.2.bn2.bias True\n","model.layer2.2.conv3.weight False\n","model.layer2.2.bn3.weight True\n","model.layer2.2.bn3.bias True\n","model.layer2.3.conv1.weight False\n","model.layer2.3.bn1.weight True\n","model.layer2.3.bn1.bias True\n","model.layer2.3.conv2.weight False\n","model.layer2.3.bn2.weight True\n","model.layer2.3.bn2.bias True\n","model.layer2.3.conv3.weight False\n","model.layer2.3.bn3.weight True\n","model.layer2.3.bn3.bias True\n","model.layer3.0.conv1.weight False\n","model.layer3.0.bn1.weight True\n","model.layer3.0.bn1.bias True\n","model.layer3.0.conv2.weight False\n","model.layer3.0.bn2.weight True\n","model.layer3.0.bn2.bias True\n","model.layer3.0.conv3.weight False\n","model.layer3.0.bn3.weight True\n","model.layer3.0.bn3.bias True\n","model.layer3.0.downsample.0.weight False\n","model.layer3.0.downsample.1.weight False\n","model.layer3.0.downsample.1.bias False\n","model.layer3.1.conv1.weight False\n","model.layer3.1.bn1.weight True\n","model.layer3.1.bn1.bias True\n","model.layer3.1.conv2.weight False\n","model.layer3.1.bn2.weight True\n","model.layer3.1.bn2.bias True\n","model.layer3.1.conv3.weight False\n","model.layer3.1.bn3.weight True\n","model.layer3.1.bn3.bias True\n","model.layer3.2.conv1.weight False\n","model.layer3.2.bn1.weight True\n","model.layer3.2.bn1.bias True\n","model.layer3.2.conv2.weight False\n","model.layer3.2.bn2.weight True\n","model.layer3.2.bn2.bias True\n","model.layer3.2.conv3.weight False\n","model.layer3.2.bn3.weight True\n","model.layer3.2.bn3.bias True\n","model.layer3.3.conv1.weight False\n","model.layer3.3.bn1.weight True\n","model.layer3.3.bn1.bias True\n","model.layer3.3.conv2.weight False\n","model.layer3.3.bn2.weight True\n","model.layer3.3.bn2.bias True\n","model.layer3.3.conv3.weight False\n","model.layer3.3.bn3.weight True\n","model.layer3.3.bn3.bias True\n","model.layer3.4.conv1.weight False\n","model.layer3.4.bn1.weight True\n","model.layer3.4.bn1.bias True\n","model.layer3.4.conv2.weight False\n","model.layer3.4.bn2.weight True\n","model.layer3.4.bn2.bias True\n","model.layer3.4.conv3.weight False\n","model.layer3.4.bn3.weight True\n","model.layer3.4.bn3.bias True\n","model.layer3.5.conv1.weight False\n","model.layer3.5.bn1.weight True\n","model.layer3.5.bn1.bias True\n","model.layer3.5.conv2.weight False\n","model.layer3.5.bn2.weight True\n","model.layer3.5.bn2.bias True\n","model.layer3.5.conv3.weight False\n","model.layer3.5.bn3.weight True\n","model.layer3.5.bn3.bias True\n","model.layer4.0.conv1.weight False\n","model.layer4.0.bn1.weight True\n","model.layer4.0.bn1.bias True\n","model.layer4.0.conv2.weight False\n","model.layer4.0.bn2.weight True\n","model.layer4.0.bn2.bias True\n","model.layer4.0.conv3.weight False\n","model.layer4.0.bn3.weight True\n","model.layer4.0.bn3.bias True\n","model.layer4.0.downsample.0.weight False\n","model.layer4.0.downsample.1.weight False\n","model.layer4.0.downsample.1.bias False\n","model.layer4.1.conv1.weight False\n","model.layer4.1.bn1.weight True\n","model.layer4.1.bn1.bias True\n","model.layer4.1.conv2.weight False\n","model.layer4.1.bn2.weight True\n","model.layer4.1.bn2.bias True\n","model.layer4.1.conv3.weight False\n","model.layer4.1.bn3.weight True\n","model.layer4.1.bn3.bias True\n","model.layer4.2.conv1.weight False\n","model.layer4.2.bn1.weight True\n","model.layer4.2.bn1.bias True\n","model.layer4.2.conv2.weight False\n","model.layer4.2.bn2.weight True\n","model.layer4.2.bn2.bias True\n","model.layer4.2.conv3.weight False\n","model.layer4.2.bn3.weight True\n","model.layer4.2.bn3.bias True\n","model.fc.weight True\n","model.fc.bias True\n","classifier.weight True\n","classifier.bias True\n"]}],"source":["for name, param in model.named_parameters():\n","    if 'bn' in name:\n","        param.requires_grad = True\n","    # elif name.startswith(('model.fc', 'classifier')):\n","    #     param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","    print(name, param.requires_grad)\n","        "]},{"cell_type":"code","execution_count":11,"id":"d4a2b64e","metadata":{},"outputs":[],"source":["def focal_binary_cross_entropy(logits, targets, gamma=2):\n","    num_label = 4\n","    l = logits.reshape(-1)\n","    t = targets.reshape(-1)\n","    p = torch.sigmoid(l)\n","    p = torch.where(t >= 0.5, p, 1-p)\n","    logp = - torch.log(torch.clamp(p, 1e-4, 1-1e-4))\n","    loss = logp*((1-p)**gamma)\n","    loss = num_label*loss.mean()\n","    return loss"]},{"cell_type":"code","execution_count":12,"id":"15567bc3","metadata":{"id":"15567bc3","outputId":"429a6a17-5af9-4dfe-fda4-f81df72d2af9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","/home/compu/.local/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n","  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkew118\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n","\n","ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help`\n","       for usage information.\n","\n","/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n","\n","ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help`\n","       for usage information.\n","\n"]},{"data":{"text/html":["wandb version 0.13.10 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/compu/Documents/kristin/material/wandb/run-20230216_181606-ohvmkgde</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/kew118/kristin/runs/ohvmkgde\" target=\"_blank\">resnet50/64/Adam0.0001/bn</a></strong> to <a href=\"https://wandb.ai/kew118/kristin\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31220/2558045091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31220/2542550905.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         )\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     return torch.batch_norm(\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0msize_prods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#criterion = focal_binary_cross_entropy\n","criterion = nn.MultiLabelSoftMarginLoss()\n","num_epochs = 100\n","train_loss = 0\n","train_acc = 0\n","test_loss = 0\n","test_acc = 0\n","\n","wandb.init(project=\"kristin\", name=\"resnet50/32/Adam0.001/bn\")\n","wandb.watch(model, criterion, log='all', log_freq=10)\n","\n","\n","# early_stopping 객체 선언(5번의 epoch 연속으로 loss 미개선 시에 조기 종료 예시)\n","# early_stopping = EarlyStopping(patience = 10, verbose = True, path = \"material1.pt\")\n","\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","\n","    for i, (images, targets) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        images = images.to(device)\n","        targets = targets.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","        train_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","        \n","        outputs = (outputs > 0.5).float()\n","        acc = (outputs == targets).float().mean()\n","        train_acc += acc\n","\n","    train_loss /= len(train_loader)\n","    train_acc /= len(train_loader)\n","\n","    model.eval()\n","    \n","    for i, (images, targets) in enumerate(test_loader):\n","        images2 = images.to(device)\n","        targets2 = targets.to(device)\n","        \n","        outputs2 = model(images2)\n","        loss2 = criterion(outputs2, targets2)\n","\n","        test_loss += loss2.item()\n","        outputs2 = (outputs2 > 0.5).float()\n","        acc = (outputs2 == targets2).float().mean()\n","        test_acc += acc\n","\n","    test_loss /= len(test_loader)\n","    test_acc /= len(test_loader)\n","    \n","    metrics = {\"train_loss\": train_loss,\n","                \"train_accuracy\": train_acc,\n","                \"test_loss\": test_loss,\n","                \"test_accuracy\": test_acc}\n","    \n","    wandb.log(metrics)\n","    # early_stopping(loss.item(), model) # 수렴 earlystop 체크\n","    \n","    # if early_stopping.early_stop: # 조건 만족 시 조기 종료\n","    #     break"]},{"cell_type":"code","execution_count":null,"id":"3e6acd8b","metadata":{"id":"3e6acd8b","outputId":"551db65d-3e59-49d2-ad9c-2ba7e91c9356"},"outputs":[],"source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    preds_list = []\n","    y_list = []\n","\n","    for i, (images, targets) in enumerate(test_loader):\n","        images = images.to(device)\n","        targets = targets.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","\n","        outputs = (outputs > 0.5).float()\n","        acc = (outputs == targets).float().mean()\n","        \n","        preds_list.append(outputs.float().cpu())\n","        y_list.append(targets.cpu())\n","    \n","    preds_list = np.concatenate(preds_list)\n","    y_list = np.concatenate(y_list)\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"id":"9bbf582a","metadata":{},"outputs":[],"source":["import sklearn.metrics as skm\n","from sklearn.metrics import multilabel_confusion_matrix\n","\n","print(skm.classification_report(y_list, preds_list))\n","matrix = multilabel_confusion_matrix(y_list, preds_list)\n","result = [mat.diagonal().sum() / mat.sum() for mat in matrix]\n","print(result)"]},{"cell_type":"code","execution_count":null,"id":"002e7f06","metadata":{"id":"002e7f06","outputId":"a0fbd9c9-628a-496b-dc2b-0492839d37a2"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 정확도(accuracy) 계산\n","accuracy = np.mean(y_list == preds_list)\n","print(f'Accuracy: {accuracy:.3f}')\n","\n","# 정밀도(precision) 계산\n","precision = precision_score(y_list, preds_list, average='micro')\n","print(f'Precision: {precision:.3f}')\n","\n","# 재현율(recall) 계산\n","recall = recall_score(y_list, preds_list, average='micro')\n","print(f'Recall: {recall:.3f}')\n","\n","# F1 점수(F1 score) 계산\n","f1 = f1_score(y_list, preds_list, average='micro')\n","print(f'F1: {f1:.3f}')"]},{"cell_type":"markdown","id":"xuOygVtjJ_rN","metadata":{"id":"xuOygVtjJ_rN"},"source":["저장된 모델 불러오기"]},{"cell_type":"code","execution_count":null,"id":"ed0b228e","metadata":{"id":"ed0b228e","outputId":"40214c7f-eb4e-4ee6-852b-4e9108198241"},"outputs":[],"source":["# 모델 불러오기 전 정의\n","class MyModel(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.resnet = models.resnet50(pretrained=True)\n","        self.classifier = nn.Linear(1000, 7)\n","\n","    def forward(self, x):\n","        x = self.resnet(x)\n","        x = self.classifier(x)\n","\n","        return x\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = MyModel().to(device)\n","print(summary(model, input_size=(1, 3, 128, 128), verbose=0))"]},{"cell_type":"code","execution_count":null,"id":"c653c2c5","metadata":{"id":"c653c2c5","outputId":"e8fdba6d-ef78-41c2-cc75-4b61fc4f5b8b"},"outputs":[],"source":["# 모델 불러오기\n","model = MyModel()\n","model.load_state_dict(torch.load('material_end.pt'))"]},{"cell_type":"code","execution_count":null,"id":"43490620","metadata":{"id":"43490620","outputId":"a043eb51-2120-4c9b-8ea2-e1585d25ec73"},"outputs":[],"source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    preds_list = []\n","    y_list = []\n","    \n","    for i, (images, targets) in enumerate(test_loader):\n","        images = images.to(device)\n","        targets = targets.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","        \n","        print(f'[예측 결과: {outputs[0]}] (실제 정답: {targets.data[0]})')\n","        \n","        if (i+1) % 10 == 0:\n","            outputs = outputs > 0.5\n","            acc = (outputs == targets).float().mean()\n","            preds_list.append(outputs.float())\n","            y_list.append(targets)\n","            print(f'{i+1}: {loss.item():.5f}, {acc.item():.5f}, {time.time() - start_time}')\n","    \n","    preds_list = np.concatenate(preds_list)\n","    y_list = np.concatenate(y_list)"]},{"cell_type":"code","execution_count":null,"id":"6ba2074d","metadata":{"id":"6ba2074d"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 정확도(accuracy) 계산\n","accuracy = np.mean(y_list == preds_list)\n","print(f'Accuracy: {accuracy:.3f}')\n","\n","# 정밀도(precision) 계산\n","precision = precision_score(y_list, preds_list, average='micro')\n","print(f'Precision: {precision:.3f}')\n","\n","# 재현율(recall) 계산\n","recall = recall_score(y_list, preds_list, average='micro')\n","print(f'Recall: {recall:.3f}')\n","\n","# F1 점수(F1 score) 계산\n","f1 = f1_score(y_list, preds_list, average='micro')\n","print(f'F1: {f1:.3f}')"]},{"cell_type":"code","execution_count":null,"id":"b53ccdfd","metadata":{"id":"b53ccdfd"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"kristin","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"2e924af7dcb5d5865ef08f57c5662edf3d112715a680ff6fa601ae201e5f87ab"}}},"nbformat":4,"nbformat_minor":5}
