{"cells":[{"cell_type":"code","execution_count":1,"id":"84dccb09","metadata":{"id":"84dccb09"},"outputs":[],"source":["import os\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","import wandb\n","import math\n","import random\n","from typing import Tuple, Sequence, Callable\n","from PIL import Image\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torch.utils.data import Dataset, DataLoader\n","from torchinfo import summary\n","from torchvision import transforms\n","from torchvision.models import *\n","from sklearn.preprocessing import LabelEncoder\n","\n","from material import MyDataset"]},{"cell_type":"code","execution_count":2,"id":"8f806c44","metadata":{},"outputs":[],"source":["# reproductability를 위한 코드\n","torch.manual_seed(1919)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(1919)\n","random.seed(1919)"]},{"cell_type":"code","execution_count":3,"id":"bbd930aa","metadata":{"id":"bbd930aa"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#gpu 사용을 위해 cuda 지정\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":4,"id":"34b905f1","metadata":{"id":"34b905f1","outputId":"87d041f9-38fa-411a-f0f1-fa8e80ed9656"},"outputs":[],"source":["# def transform(proba):\n","#     t = transforms.Compose([\n","#         transforms.Resize((224, 224)),\n","#         transforms.RandomHorizontalFlip(p=proba),\n","#         transforms.RandomVerticalFlip(p=proba),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize(\n","#             [0.485, 0.456, 0.406],\n","#             [0.229, 0.224, 0.225]\n","#         )\n","#     ])\n","#     return t"]},{"cell_type":"code","execution_count":5,"id":"45c74613","metadata":{},"outputs":[],"source":["# trainsets = []\n","# dirs = [\"leather/\", \"mesh_knit/\", \"suede/\", \"nylon/\"]\n","# prob = [0.25, 0.5, 1, 0.75]\n","\n","# for i in range(4):\n","#     dataset = MyDataset(dir='/home/compu/Documents/exports/material_merge/train/'+dirs[i],\n","#                         image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","#                         transforms=transform(prob[i]))\n","#     trainsets.append(dataset)\n","#     print(len(dataset))\n","\n","# trainset = torch.utils.data.ConcatDataset(trainsets)"]},{"cell_type":"code","execution_count":6,"id":"599cb9f2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["학습 데이터셋 크기: 4950\n","테스트 데이터셋 크기: 1455\n"]}],"source":["transforms_train = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        [0.485, 0.456, 0.406],\n","        [0.229, 0.224, 0.225]\n","    )\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        [0.485, 0.456, 0.406],\n","        [0.229, 0.224, 0.225]\n","    )\n","])\n","\n","trainset = MyDataset(dir='/home/compu/Documents/exports/material_merge/train/',\n","                     image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","                     transforms=transforms_train)\n","\n","testset = MyDataset(dir='/home/compu/Documents/exports/material_merge/test/',\n","                    image_ids='/home/compu/Documents/exports/newfile_material_merge.json',\n","                    transforms=transforms_test)\n","\n","train_loader = DataLoader(trainset, batch_size=32, num_workers=8)\n","test_loader = DataLoader(testset, batch_size=32, num_workers=8)\n","\n","print('학습 데이터셋 크기:', len(trainset))\n","print('테스트 데이터셋 크기:', len(testset))"]},{"cell_type":"code","execution_count":7,"id":"417bdedb","metadata":{"id":"417bdedb"},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":8,"id":"915f2143","metadata":{"id":"915f2143","outputId":"68c1b339-70c1-44e3-fa3a-ae0badb41cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["===============================================================================================\n","Layer (type:depth-idx)                        Output Shape              Param #\n","===============================================================================================\n","MyModel                                       [1, 4]                    --\n","├─ResNet: 1-1                                 [1, 1000]                 --\n","│    └─Conv2d: 2-1                            [1, 64, 112, 112]         9,408\n","│    └─BatchNorm2d: 2-2                       [1, 64, 112, 112]         128\n","│    └─ReLU: 2-3                              [1, 64, 112, 112]         --\n","│    └─MaxPool2d: 2-4                         [1, 64, 56, 56]           --\n","│    └─Sequential: 2-5                        [1, 64, 56, 56]           --\n","│    │    └─BasicBlock: 3-1                   [1, 64, 56, 56]           73,984\n","│    │    └─BasicBlock: 3-2                   [1, 64, 56, 56]           73,984\n","│    │    └─BasicBlock: 3-3                   [1, 64, 56, 56]           73,984\n","│    └─Sequential: 2-6                        [1, 128, 28, 28]          --\n","│    │    └─BasicBlock: 3-4                   [1, 128, 28, 28]          230,144\n","│    │    └─BasicBlock: 3-5                   [1, 128, 28, 28]          295,424\n","│    │    └─BasicBlock: 3-6                   [1, 128, 28, 28]          295,424\n","│    │    └─BasicBlock: 3-7                   [1, 128, 28, 28]          295,424\n","│    └─Sequential: 2-7                        [1, 256, 14, 14]          --\n","│    │    └─BasicBlock: 3-8                   [1, 256, 14, 14]          919,040\n","│    │    └─BasicBlock: 3-9                   [1, 256, 14, 14]          1,180,672\n","│    │    └─BasicBlock: 3-10                  [1, 256, 14, 14]          1,180,672\n","│    │    └─BasicBlock: 3-11                  [1, 256, 14, 14]          1,180,672\n","│    │    └─BasicBlock: 3-12                  [1, 256, 14, 14]          1,180,672\n","│    │    └─BasicBlock: 3-13                  [1, 256, 14, 14]          1,180,672\n","│    └─Sequential: 2-8                        [1, 512, 7, 7]            --\n","│    │    └─BasicBlock: 3-14                  [1, 512, 7, 7]            3,673,088\n","│    │    └─BasicBlock: 3-15                  [1, 512, 7, 7]            4,720,640\n","│    │    └─BasicBlock: 3-16                  [1, 512, 7, 7]            4,720,640\n","│    └─AdaptiveAvgPool2d: 2-9                 [1, 512, 1, 1]            --\n","│    └─Linear: 2-10                           [1, 1000]                 513,000\n","├─Linear: 1-2                                 [1, 4]                    4,004\n","===============================================================================================\n","Total params: 21,801,676\n","Trainable params: 21,801,676\n","Non-trainable params: 0\n","Total mult-adds (G): 3.66\n","===============================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 59.82\n","Params size (MB): 87.21\n","Estimated Total Size (MB): 147.63\n","===============================================================================================\n"]}],"source":["class MyModel(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.model = resnet34(pretrained=False)\n","        self.classifier = nn.Linear(1000, 4)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.classifier(x)\n","        return x\n","\n","model = MyModel().to(device)\n","print(summary(model, input_size=(1, 3, 224, 224), verbose=0))"]},{"cell_type":"code","execution_count":11,"id":"d4a2b64e","metadata":{},"outputs":[],"source":["def focal_binary_cross_entropy(logits, targets, gamma=2):\n","    num_label = 4\n","    l = logits.reshape(-1)\n","    t = targets.reshape(-1)\n","    p = torch.sigmoid(l)\n","    p = torch.where(t >= 0.5, p, 1-p)\n","    logp = - torch.log(torch.clamp(p, 1e-4, 1-1e-4))\n","    loss = logp*((1-p)**gamma)\n","    loss = num_label*loss.mean()\n","    return loss"]},{"cell_type":"code","execution_count":12,"id":"15567bc3","metadata":{"id":"15567bc3","outputId":"429a6a17-5af9-4dfe-fda4-f81df72d2af9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","/home/compu/.local/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n","  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkew118\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.10 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/compu/Documents/kristin/material/wandb/run-20230215_142100-l0zm1z46</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/kew118/kristin/runs/l0zm1z46\" target=\"_blank\">resnet34/T/focal</a></strong> to <a href=\"https://wandb.ai/kew118/kristin\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loss decreased (inf --> 0.457243).  Saving model ...\n","loss decreased (0.457243 --> 0.425760).  Saving model ...\n","loss decreased (0.425760 --> 0.388231).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.388231 --> 0.386843).  Saving model ...\n","loss decreased (0.386843 --> 0.334968).  Saving model ...\n","loss decreased (0.334968 --> 0.314879).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.314879 --> 0.280909).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","loss decreased (0.280909 --> 0.223476).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.223476 --> 0.204811).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.204811 --> 0.189913).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","loss decreased (0.189913 --> 0.149442).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n","loss decreased (0.149442 --> 0.144917).  Saving model ...\n","loss decreased (0.144917 --> 0.137207).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.137207 --> 0.117266).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","loss decreased (0.117266 --> 0.075616).  Saving model ...\n","loss decreased (0.075616 --> 0.075140).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n","loss decreased (0.075140 --> 0.073735).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","loss decreased (0.073735 --> 0.030145).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n","EarlyStopping counter: 4 out of 10\n","EarlyStopping counter: 5 out of 10\n","loss decreased (0.030145 --> 0.026851).  Saving model ...\n","loss decreased (0.026851 --> 0.021747).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n","EarlyStopping counter: 4 out of 10\n","EarlyStopping counter: 5 out of 10\n","EarlyStopping counter: 6 out of 10\n","EarlyStopping counter: 7 out of 10\n","loss decreased (0.021747 --> 0.019512).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n","EarlyStopping counter: 4 out of 10\n","EarlyStopping counter: 5 out of 10\n","EarlyStopping counter: 6 out of 10\n","loss decreased (0.019512 --> 0.011561).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","loss decreased (0.011561 --> 0.010597).  Saving model ...\n","EarlyStopping counter: 1 out of 10\n","EarlyStopping counter: 2 out of 10\n","EarlyStopping counter: 3 out of 10\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_739/1059752356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/kristin/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","criterion = focal_binary_cross_entropy\n","# criterion = nn.MultiLabelSoftMarginLoss()\n","num_epochs = 100\n","train_loss = 0\n","train_acc = 0\n","test_loss = 0\n","test_acc = 0\n","\n","wandb.init(project=\"kristin\", name=\"resnet34/T/focal\")\n","wandb.watch(model, criterion, log='all', log_freq=10)\n","\n","\n","# early_stopping 객체 선언(5번의 epoch 연속으로 loss 미개선 시에 조기 종료 예시)\n","early_stopping = EarlyStopping(patience = 10, verbose = True, path = \"material1.pt\")\n","\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","\n","    for i, (images, targets) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        images = images.to(device)\n","        targets = targets.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","        train_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","        \n","        outputs = (outputs > 0.5).float()\n","        acc = (outputs == targets).float().mean()\n","        train_acc += acc\n","\n","    train_loss /= len(train_loader)\n","    train_acc /= len(train_loader)\n","\n","    model.eval()\n","    \n","    for i, (images, targets) in enumerate(test_loader):\n","        images2 = images.to(device)\n","        targets2 = targets.to(device)\n","        \n","        outputs2 = model(images2)\n","        loss2 = criterion(outputs2, targets2)\n","\n","        test_loss += loss2.item()\n","        outputs2 = (outputs2 > 0.5).float()\n","        acc = (outputs2 == targets2).float().mean()\n","        test_acc += acc\n","\n","    test_loss /= len(test_loader)\n","    test_acc /= len(test_loader)\n","    \n","    metrics = {\"train_loss\": train_loss,\n","                \"train_accuracy\": train_acc,\n","                \"test_loss\": test_loss,\n","                \"test_accuracy\": test_acc}\n","    \n","    wandb.log(metrics)\n","    early_stopping(loss.item(), model) # 수렴 earlystop 체크\n","    \n","    if early_stopping.early_stop: # 조건 만족 시 조기 종료\n","        break"]},{"cell_type":"code","execution_count":null,"id":"3e6acd8b","metadata":{"id":"3e6acd8b","outputId":"551db65d-3e59-49d2-ad9c-2ba7e91c9356"},"outputs":[],"source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    preds_list = []\n","    y_list = []\n","\n","    for i, (images, targets) in enumerate(test_loader):\n","        images = images.to(device)\n","        targets = targets.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","\n","        outputs = (outputs > 0.5).float()\n","        acc = (outputs == targets).float().mean()\n","        \n","        preds_list.append(outputs.float().cpu())\n","        y_list.append(targets.cpu())\n","    \n","    preds_list = np.concatenate(preds_list)\n","    y_list = np.concatenate(y_list)\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"id":"9bbf582a","metadata":{},"outputs":[],"source":["import sklearn.metrics as skm\n","from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n","\n","print(skm.classification_report(y_list, preds_list))\n","matrix = multilabel_confusion_matrix(y_list, preds_list)\n","result = [mat.diagonal().sum() / mat.sum() for mat in matrix]\n","print(result)"]},{"cell_type":"code","execution_count":null,"id":"002e7f06","metadata":{"id":"002e7f06","outputId":"a0fbd9c9-628a-496b-dc2b-0492839d37a2"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 정확도(accuracy) 계산\n","accuracy = np.mean(y_list == preds_list)\n","print(f'Accuracy: {accuracy:.3f}')\n","\n","# 정밀도(precision) 계산\n","precision = precision_score(y_list, preds_list, average='micro')\n","print(f'Precision: {precision:.3f}')\n","\n","# 재현율(recall) 계산\n","recall = recall_score(y_list, preds_list, average='micro')\n","print(f'Recall: {recall:.3f}')\n","\n","# F1 점수(F1 score) 계산\n","f1 = f1_score(y_list, preds_list, average='micro')\n","print(f'F1: {f1:.3f}')"]},{"cell_type":"markdown","id":"xuOygVtjJ_rN","metadata":{"id":"xuOygVtjJ_rN"},"source":["저장된 모델 불러오기"]},{"cell_type":"code","execution_count":null,"id":"ed0b228e","metadata":{"id":"ed0b228e","outputId":"40214c7f-eb4e-4ee6-852b-4e9108198241"},"outputs":[],"source":["# 모델 불러오기 전 정의\n","class MyModel(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.resnet = resnet50(pretrained=True)\n","        self.classifier = nn.Linear(1000, 7)\n","\n","    def forward(self, x):\n","        x = self.resnet(x)\n","        x = self.classifier(x)\n","\n","        return x\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = MyModel().to(device)\n","print(summary(model, input_size=(1, 3, 128, 128), verbose=0))"]},{"cell_type":"code","execution_count":null,"id":"c653c2c5","metadata":{"id":"c653c2c5","outputId":"e8fdba6d-ef78-41c2-cc75-4b61fc4f5b8b"},"outputs":[],"source":["# 모델 불러오기\n","model = MyModel()\n","model.load_state_dict(torch.load('material_end.pt'))"]},{"cell_type":"code","execution_count":null,"id":"43490620","metadata":{"id":"43490620","outputId":"a043eb51-2120-4c9b-8ea2-e1585d25ec73"},"outputs":[],"source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    preds_list = []\n","    y_list = []\n","    \n","    for i, (images, targets) in enumerate(test_loader):\n","        images = images.to(device)\n","        targets = targets.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","        \n","        print(f'[예측 결과: {outputs[0]}] (실제 정답: {targets.data[0]})')\n","        \n","        if (i+1) % 10 == 0:\n","            outputs = outputs > 0.5\n","            acc = (outputs == targets).float().mean()\n","            preds_list.append(outputs.float())\n","            y_list.append(targets)\n","            print(f'{i+1}: {loss.item():.5f}, {acc.item():.5f}, {time.time() - start_time}')\n","    \n","    preds_list = np.concatenate(preds_list)\n","    y_list = np.concatenate(y_list)"]},{"cell_type":"code","execution_count":null,"id":"6ba2074d","metadata":{"id":"6ba2074d"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 정확도(accuracy) 계산\n","accuracy = np.mean(y_list == preds_list)\n","print(f'Accuracy: {accuracy:.3f}')\n","\n","# 정밀도(precision) 계산\n","precision = precision_score(y_list, preds_list, average='micro')\n","print(f'Precision: {precision:.3f}')\n","\n","# 재현율(recall) 계산\n","recall = recall_score(y_list, preds_list, average='micro')\n","print(f'Recall: {recall:.3f}')\n","\n","# F1 점수(F1 score) 계산\n","f1 = f1_score(y_list, preds_list, average='micro')\n","print(f'F1: {f1:.3f}')"]},{"cell_type":"code","execution_count":null,"id":"b53ccdfd","metadata":{"id":"b53ccdfd"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"kristin","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"2e924af7dcb5d5865ef08f57c5662edf3d112715a680ff6fa601ae201e5f87ab"}}},"nbformat":4,"nbformat_minor":5}
